# scanner_logic.py
import json
import logging
import os
import time
import re # Przeniesiony import re na gÃ³rÄ™
from datetime import datetime
from pathlib import Path

import config_manager # ZaÅ‚oÅ¼enie: ten plik istnieje i dziaÅ‚a poprawnie

# Konfiguracja loggera
def setup_logger(log_dir="logs", enable_file_logging=None):
    """Konfiguruje i zwraca logger z opcjonalnym zapisem do pliku."""
    if enable_file_logging is None:
        enable_file_logging = config_manager.get_config_value(
            "enable_file_logging", False
        )

    logger = logging.getLogger("scanner")
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()

    formatter = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
    )

    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    if enable_file_logging:
        log_path = Path(log_dir)
        log_path.mkdir(exist_ok=True)
        log_file = log_path / f"scanner_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        file_handler = logging.FileHandler(log_file, encoding="utf-8")
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    return logger

logger = setup_logger()

IMAGE_EXTENSIONS = (
    ".jpg", ".jpeg", ".jpe", ".jfif",
    ".png", ".apng",
    ".gif",
    ".bmp", ".dib",
    ".webp",
    ".tiff", ".tif",
    ".svg", ".svgz",
    ".ico",
    ".avif",
    ".heic", ".heif",
)

def get_file_size_readable(size_bytes):
    """Konwertuje rozmiar pliku w bajtach na czytelny format."""
    # logger.debug(f"Konwersja rozmiaru pliku: {size_bytes} bajtÃ³w") # MoÅ¼e byÄ‡ zbyt gadatliwe
    if size_bytes == 0:
        return "0 B"
    size_name = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0
    # Ensure size_bytes is float for division if it's large
    size_bytes_float = float(size_bytes)
    while size_bytes_float >= 1024 and i < len(size_name) - 1:
        size_bytes_float /= 1024.0
        i += 1
    result = f"{size_bytes_float:.2f} {size_name[i]}"
    # logger.debug(f"Wynik konwersji: {result}")
    return result

def get_folder_stats(folder_path):
    """
    Zbiera podstawowe statystyki dotyczÄ…ce folderu.
    UWAGA: Ta funkcja wykonuje oddzielne skanowanie. W gÅ‚Ã³wnym przepÅ‚ywie
    process_folder statystyki sÄ… zbierane bardziej efektywnie.
    MoÅ¼e byÄ‡ uÅ¼yteczna do szybkiego, niezaleÅ¼nego sprawdzenia folderu.
    """
    logger.info(f"Zbieranie statystyk (get_folder_stats) dla folderu: {folder_path}")
    total_size_bytes = 0
    file_count = 0
    subdir_count = 0
    # archive_count jest tu interpretowane jako file_count
    # (zgodnie z wczeÅ›niejszym uÅ¼yciem w tej funkcji)
    items_processed_for_stats = 0

    try:
        for entry in os.scandir(folder_path):
            items_processed_for_stats += 1
            if entry.is_file(follow_symlinks=False) and entry.name.lower() != "index.json":
                try:
                    stat_info = entry.stat(follow_symlinks=False)
                    file_size = stat_info.st_size
                    file_count += 1
                    total_size_bytes += file_size
                    logger.debug(f"Stat: Znaleziono plik: {entry.name} ({file_size} bajtÃ³w)")
                except OSError as e:
                    logger.error(f"Stat: BÅ‚Ä…d dostÄ™pu do pliku {entry.name}: {e}")
            elif entry.is_dir(follow_symlinks=False):
                subdir_count += 1
                logger.debug(f"Stat: Znaleziono podfolder: {entry.name}")
    except OSError as e:
        logger.error(f"Stat: BÅ‚Ä…d podczas skanowania folderu {folder_path}: {e}")

    stats = {
        "path": os.path.abspath(folder_path),
        "total_size_bytes": total_size_bytes,
        "total_size_readable": get_file_size_readable(total_size_bytes),
        "file_count": file_count,
        "subdir_count": subdir_count,
        "archive_count": file_count, # Zgodnie z logikÄ… z oryginalnego kodu
        "scan_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    logger.info(f"Statystyki folderu (get_folder_stats) {folder_path}: {stats}")
    return stats


def load_learning_data():
    """Wczytuje dane uczenia siÄ™ z pliku JSON"""
    try:
        learning_file = config_manager.get_config_value("learning_data_file", "learning_data.json")
        if os.path.exists(learning_file):
            with open(learning_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(f"Wczytano {len(data)} wpisÃ³w z danych uczenia siÄ™ ({learning_file}).")
                
                # Analiza jakoÅ›ci danych uczenia
                valid_entries = 0
                for entry in data:
                    if entry.get("archive_basename") and entry.get("image_basename"):
                        valid_entries += 1
                
                logger.info(f"ğŸ“Š JakoÅ›Ä‡ danych uczenia: {valid_entries}/{len(data)} prawidÅ‚owych wpisÃ³w")
                
                return data
        logger.info(f"Plik danych uczenia siÄ™ ({learning_file}) nie istnieje.")
        return []
    except json.JSONDecodeError as e:
        logger.error(f"BÅ‚Ä…d dekodowania JSON w pliku danych uczenia siÄ™: {e}")
        return []
    except Exception as e:
        logger.error(f"BÅ‚Ä…d wczytywania danych uczenia siÄ™: {e}", exc_info=True)
        return []

def find_matching_preview_for_file(base_filename, image_files_in_folder, learning_data=None):
    """
    PrzywrÃ³cona oryginalna funkcja + RZECZYWISTE wzorce (nie mapowania!)
    """
    logger.debug(f"ğŸ” Szukam podglÄ…du dla: '{base_filename}'")

    if not base_filename:
        logger.warning("âŒ Przekazano pustÄ… nazwÄ™")
        return None

    # 1. NAJPIERW: Zastosuj WZORCE z uczenia (nie mapowania!)
    if learning_data:
        learned_match = apply_smart_patterns(base_filename, image_files_in_folder, learning_data)
        if learned_match:
            return learned_match

    # 2. ORYGINALNY ALGORYTM (ktÃ³ry dziaÅ‚aÅ‚!)
    normalized_base_filename = base_filename.lower().strip()
    
    # Podstawowe warianty
    name_variants = set([normalized_base_filename])
    name_variants.add(normalized_base_filename.replace("_", " "))
    name_variants.add(normalized_base_filename.replace(" ", "_"))
    name_variants.add(normalized_base_filename.replace("-", " "))
    name_variants.add(normalized_base_filename.replace(" ", "-"))
    name_variants.add(normalized_base_filename.replace("_", "-"))
    name_variants.add(normalized_base_filename.replace("-", "_"))
    
    # Dodaj warianty z typowymi sufiksami
    extended_variants = set(name_variants)
    common_suffixes = ["001", "preview", "thumb", "1", "2", "3", "0", "cover"]
    for variant in name_variants:
        for separator in ["_", "-", " "]:
            for suffix in common_suffixes:
                extended_variants.add(variant + separator + suffix)
    
    # SprawdÅº dokÅ‚adne dopasowania
    for img_full_path in image_files_in_folder:
        img_name = os.path.basename(img_full_path)
        img_base, img_ext = os.path.splitext(img_name)
        if img_ext.lower() not in IMAGE_EXTENSIONS:
            continue
            
        img_base_lower = img_base.lower().strip()
        if img_base_lower in extended_variants:
            logger.info(f"âœ… Dopasowanie: '{base_filename}' â†” '{img_name}'")
            return img_full_path
    
    # SprawdÅº prefiksy
    for img_full_path in image_files_in_folder:
        img_name = os.path.basename(img_full_path)
        img_base, img_ext = os.path.splitext(img_name)
        if img_ext.lower() not in IMAGE_EXTENSIONS:
            continue
            
        img_base_lower = img_base.lower().strip()
        for variant in name_variants:
            if len(variant) >= 3 and img_base_lower.startswith(variant):
                remaining = img_base_lower[len(variant):]
                if not remaining or remaining[0] in [' ', '_', '-'] or remaining[0].isdigit():
                    logger.info(f"âœ… Dopasowanie prefiksu: '{base_filename}' â†” '{img_name}'")
                    return img_full_path

    logger.debug(f"âŒ Nie znaleziono podglÄ…du dla: '{base_filename}'")
    return None

def apply_smart_patterns(base_filename, image_files_in_folder, learning_data):
    """
    RZECZYWISTE wyciÄ…ganie wzorcÃ³w - nie mapowania!
    """
    base_lower = base_filename.lower().strip()
    
    # Analizuj wszystkie przykÅ‚ady uczenia, aby znaleÅºÄ‡ WZORCE
    separator_patterns = analyze_separator_patterns(learning_data)
    space_patterns = analyze_space_patterns(learning_data)
    suffix_patterns = analyze_suffix_patterns(learning_data)
    
    logger.debug(f"ğŸ“š Znalezione wzorce - separatory: {len(separator_patterns)}, spacje: {len(space_patterns)}, sufiksy: {len(suffix_patterns)}")
    
    # Zastosuj wzorce separatorÃ³w
    for pattern in separator_patterns:
        if pattern['confidence'] >= 0.5:  # Tylko pewne wzorce
            modified_name = apply_separator_pattern(base_lower, pattern)
            if modified_name != base_lower:
                match = find_image_by_basename(modified_name, image_files_in_folder)
                if match:
                    logger.info(f"ğŸ“ WZORZEC SEPARATORA ({pattern['from']}â†’{pattern['to']}): '{base_filename}' â†” '{os.path.basename(match)}'")
                    return match
    
    # Zastosuj wzorce spacji
    for pattern in space_patterns:
        if pattern['confidence'] >= 0.5:
            modified_name = apply_space_pattern(base_lower, pattern)
            if modified_name != base_lower:
                match = find_image_by_basename(modified_name, image_files_in_folder)
                if match:
                    logger.info(f"ğŸ“ WZORZEC SPACJI: '{base_filename}' â†” '{os.path.basename(match)}'")
                    return match
    
    return None

def analyze_separator_patterns(learning_data):
    """Analizuje wzorce separatorÃ³w z przykÅ‚adÃ³w"""
    patterns = {}
    
    for entry in learning_data:
        archive_base = entry.get("archive_basename", "").lower().strip()
        image_base = entry.get("image_basename", "").lower().strip()
        
        if not archive_base or not image_base:
            continue
            
        # SprawdÅº czy to wzorzec _ â†’ .
        if '_' in archive_base and '.' in image_base:
            archive_clean = archive_base.replace('_', '')
            image_clean = image_base.replace('.', '')
            if archive_clean == image_clean:
                key = "_to_dot"
                if key not in patterns:
                    patterns[key] = {'from': '_', 'to': '.', 'count': 0, 'examples': []}
                patterns[key]['count'] += 1
                patterns[key]['examples'].append((archive_base, image_base))
        
        # SprawdÅº inne wzorce separatorÃ³w...
        # MoÅ¼esz dodaÄ‡ wiÄ™cej wzorcÃ³w tutaj
    
    # Oblicz confidence dla kaÅ¼dego wzorca
    total_examples = len(learning_data)
    result = []
    for pattern_data in patterns.values():
        confidence = pattern_data['count'] / max(total_examples, 1)
        result.append({
            'from': pattern_data['from'],
            'to': pattern_data['to'],
            'confidence': confidence,
            'count': pattern_data['count']
        })
    
    return result

def analyze_space_patterns(learning_data):
    """Analizuje wzorce spacji"""
    patterns = {}
    
    for entry in learning_data:
        archive_base = entry.get("archive_basename", "").lower().strip()
        image_base = entry.get("image_basename", "").lower().strip()
        
        if not archive_base or not image_base:
            continue
            
        # SprawdÅº wzorzec _ â†’ spacja
        if '_' in archive_base and ' ' in image_base:
            archive_as_spaces = archive_base.replace('_', ' ')
            if archive_as_spaces == image_base:
                key = "underscore_to_space"
                if key not in patterns:
                    patterns[key] = {'pattern': key, 'count': 0}
                patterns[key]['count'] += 1
    
    # Oblicz confidence
    total_examples = len(learning_data)
    result = []
    for pattern_data in patterns.values():
        confidence = pattern_data['count'] / max(total_examples, 1)
        result.append({
            'pattern': pattern_data['pattern'],
            'confidence': confidence,
            'count': pattern_data['count']
        })
    
    return result

def analyze_suffix_patterns(learning_data):
    """Analizuje wzorce sufiksÃ³w"""
    # Implementacja dla sufiksÃ³w - na razie pusta
    return []

def apply_separator_pattern(base_name, pattern):
    """Stosuje wzorzec separatora"""
    if pattern['from'] == '_' and pattern['to'] == '.':
        return base_name.replace('_', '.')
    return base_name

def apply_space_pattern(base_name, pattern):
    """Stosuje wzorzec spacji"""
    if pattern['pattern'] == 'underscore_to_space':
        return base_name.replace('_', ' ')
    return base_name

def find_image_by_basename(target_basename, image_files_in_folder):
    """Znajduje obraz po basename"""
    for img_path in image_files_in_folder:
        img_name = os.path.basename(img_path)
        img_base, img_ext = os.path.splitext(img_name)
        if img_ext.lower() in IMAGE_EXTENSIONS:
            if img_base.lower().strip() == target_basename:
                return img_path
    return None

def debug_name_matching(base_filename, image_files_in_folder_paths):
    """
    Funkcja debugowa do sprawdzenia wszystkich moÅ¼liwych dopasowaÅ„.
    UÅ¼yj do diagnozowania problemÃ³w z dopasowywaniem nazw.
    `image_files_in_folder_paths` to lista peÅ‚nych Å›cieÅ¼ek.
    """
    print(f"\n--- DEBUG NAME MATCHING dla: '{base_filename}' ---")

    # Replikacja logiki generowania wariantÃ³w z find_matching_preview_for_file
    normalized_base_filename = base_filename.lower().strip()
    name_variants = set()
    name_variants.add(normalized_base_filename)
    name_variants.add(normalized_base_filename.replace("_", " "))
    # ... (reszta logiki generowania name_variants i extended_variants_with_suffixes jak w find_matching_preview_for_file)
    # Dla uproszczenia tego przykÅ‚adu, skopiujÄ™ tylko podstawowÄ… czÄ™Å›Ä‡, ale powinna byÄ‡ peÅ‚na.
    temp_variants = set([normalized_base_filename, normalized_base_filename.replace("_", " "), normalized_base_filename.replace(" ", "_")])
    print(f"ğŸ“ Podstawowe warianty testowe dla '{base_filename}': {sorted(list(temp_variants))}")
    # Tu powinna byÄ‡ peÅ‚na logika extended_variants_with_suffixes

    image_filenames = [os.path.basename(p) for p in image_files_in_folder_paths]
    print(f"ğŸ–¼ï¸ DostÄ™pne obrazy (nazwy): {image_filenames}")

    # Testowanie z find_matching_preview_for_file
    # NaleÅ¼y zaÅ‚adowaÄ‡ learning_data, jeÅ›li ma byÄ‡ testowane
    # learning_data_for_debug = load_learning_data()
    # match = find_matching_preview_for_file(base_filename, image_files_in_folder_paths, learning_data_for_debug)

    # Uproszczone testowanie (bezpoÅ›rednie)
    for img_path in image_files_in_folder_paths:
        img_name_with_ext = os.path.basename(img_path)
        img_base_name, img_ext = os.path.splitext(img_name_with_ext)

        if img_ext.lower() not in IMAGE_EXTENSIONS:
            continue

        img_base_lower_stripped = img_base_name.lower().strip()
        print(f"  ğŸ” Sprawdzam obraz: '{img_name_with_ext}' (baza: '{img_base_lower_stripped}')")

        # Tutaj moÅ¼na by dodaÄ‡ logikÄ™ sprawdzania dopasowania z debug_name_matching
        # np. czy img_base_lower_stripped jest w extended_variants_with_suffixes
        # lub czy img_base_lower_stripped.startswith(variant) itd.
        # Dla zwiÄ™zÅ‚oÅ›ci pomijam peÅ‚nÄ… reimplementacjÄ™ logiki dopasowania tutaj.
        # Najlepiej byÅ‚oby wywoÅ‚aÄ‡ find_matching_preview_for_file i przeanalizowaÄ‡ jego logi DEBUG.

    print(f"--- KONIEC DEBUG NAME MATCHING dla: '{base_filename}' ---")


def log_file_matching_debug(folder_path, progress_callback=None):
    """
    Funkcja debugowa do sprawdzenia dopasowywania plikÃ³w.
    UÅ¼yj jej do diagnozowania problemÃ³w z dopasowywaniem.
    """
    logger.info(f"ğŸ” DEBUG MATCHING: Analiza dopasowywania plikÃ³w w: {folder_path}")
    if progress_callback: progress_callback(f"ğŸ” Rozpoczynam debugowanie dopasowaÅ„ w: {folder_path}")

    all_files_in_dir = []
    try:
        logger.debug(f"Debug Matching: SkanujÄ™ {folder_path} dla plikÃ³w...")
        for entry in os.scandir(folder_path):
            if entry.is_file(follow_symlinks=False):
                all_files_in_dir.append(entry.name)
        logger.debug(f"Debug Matching: Znaleziono {len(all_files_in_dir)} plikÃ³w: {all_files_in_dir}")
    except OSError as e:
        logger.error(f"Debug Matching: BÅ‚Ä…d listowania plikÃ³w w {folder_path}: {e}")
        if progress_callback: progress_callback(f"Debug Matching: BÅ‚Ä…d listowania {folder_path}: {e}")
        return

    image_filenames = [f for f in all_files_in_dir if any(f.lower().endswith(ext) for ext in IMAGE_EXTENSIONS)]
    other_filenames = [f for f in all_files_in_dir if f not in image_filenames and f.lower() != "index.json"]

    logger.info(f"Debug Matching: Pliki obrazÃ³w ({len(image_filenames)}): {image_filenames}")
    logger.info(f"Debug Matching: Inne pliki ({len(other_filenames)}): {other_filenames}")

    full_path_image_files = [os.path.join(folder_path, img_name) for img_name in image_filenames]
    learning_data = load_learning_data() # ZaÅ‚aduj dane uczenia siÄ™ do testu

    matches_found = 0
    for other_file_name in other_filenames:
        base_name_of_other_file, _ = os.path.splitext(other_file_name)
        
        # WÅ‚Ä…cz szczegÃ³Å‚owe logowanie dla tej konkretnej operacji
        # MoÅ¼na tymczasowo podnieÅ›Ä‡ poziom loggera find_matching_preview_for_file, jeÅ›li jest oddzielny,
        # lub po prostu polegaÄ‡ na globalnym poziomie DEBUG.
        
        matched_preview_path = find_matching_preview_for_file(base_name_of_other_file, full_path_image_files, learning_data)

        if matched_preview_path:
            matches_found += 1
            logger.info(f"Debug Matching: âœ… DOPASOWANIE: '{other_file_name}' â†” '{os.path.basename(matched_preview_path)}'")
            if progress_callback: progress_callback(f"Debug Dopasowano: {other_file_name} â†” {os.path.basename(matched_preview_path)}")
        else:
            logger.info(f"Debug Matching: âŒ BRAK DOPASOWANIA: '{other_file_name}' (szukano dla bazy '{base_name_of_other_file}')")
            if progress_callback: progress_callback(f"Debug Brak podglÄ…du dla: {other_file_name}")
            # Dodatkowe wywoÅ‚anie debug_name_matching dla nieudanych przypadkÃ³w
            debug_name_matching(base_name_of_other_file, full_path_image_files)


    logger.info(f"Debug Matching: ğŸ“Š PODSUMOWANIE: {matches_found}/{len(other_filenames)} innych plikÃ³w ma znaleziony podglÄ…d.")
    if progress_callback: progress_callback(f"ğŸ” ZakoÅ„czono debugowanie dopasowaÅ„ w: {folder_path}")


def process_folder(folder_path, progress_callback=None):
    logger.info(f"ğŸ”„ Rozpoczynam przetwarzanie folderu: {folder_path}")
    if progress_callback:
        progress_callback(f"ğŸ”„ Przetwarzanie folderu: {folder_path}")

    learning_data = load_learning_data()
    # (Logowanie danych uczenia siÄ™ jest juÅ¼ w load_learning_data)

    # --- Sprawdzenia folderu ---
    try:
        logger.debug(f"Sprawdzanie istnienia: {folder_path}")
        if not os.path.exists(folder_path):
            msg = f"âŒ Folder nie istnieje: {folder_path}"
            logger.error(msg)
            if progress_callback: progress_callback(msg)
            return
        
        logger.debug(f"Sprawdzanie dostÄ™pu (R_OK): {folder_path}")
        if not os.access(folder_path, os.R_OK):
            msg = f"âŒ Brak uprawnieÅ„ do odczytu folderu: {folder_path}"
            logger.error(msg)
            if progress_callback: progress_callback(msg)
            return

        logger.debug(f"Sprawdzanie czy jest linkiem symbolicznym: {folder_path}")
        if os.path.islink(folder_path):
            msg = f"âš ï¸ Pomijam przetwarzanie, folder jest linkiem symbolicznym: {folder_path}"
            logger.warning(msg)
            if progress_callback: progress_callback(msg)
            return
            
    except OSError as e: # Np. zbyt dÅ‚uga Å›cieÅ¼ka (Windows)
        msg = f"âŒ BÅ‚Ä…d OSError podczas wstÄ™pnych sprawdzeÅ„ folderu {folder_path}: {e}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)
        return
    except Exception as e: # Inne, mniej spodziewane bÅ‚Ä™dy
        msg = f"âŒ Nieoczekiwany bÅ‚Ä…d podczas wstÄ™pnych sprawdzeÅ„ folderu {folder_path}: {e}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)
        return

    # --- Inicjalizacja danych dla index.json ---
    index_data = {
        "folder_info": {
            "path": os.path.abspath(folder_path),
            "total_size_bytes": 0,
            "file_count": 0, # Liczba plikÃ³w (nie-obrazÃ³w i nie index.json) + obrazy
            "subdir_count": 0,
            "archive_count": 0, # WczeÅ›niej byÅ‚o toÅ¼same z file_count, utrzymujÄ™ dla spÃ³jnoÅ›ci
            "scan_date": None 
        },
        "files_with_previews": [],
        "files_without_previews": [],
        "other_images": [], # Obrazy, ktÃ³re nie sÄ… podglÄ…dami
    }

    # Listy do przechowywania szczegÃ³Å‚Ã³w o plikach przed dopasowaniem
    # KaÅ¼dy element to krotka: (name, full_path, size_bytes)
    image_file_details = [] 
    other_file_details = [] # Dla plikÃ³w niebÄ™dÄ…cych obrazami
    subdirectories_to_scan_recursively = []

    # --- Skanowanie zawartoÅ›ci folderu za pomocÄ… os.scandir ---
    logger.info(f"ğŸ“‚ Rozpoczynam skanowanie zawartoÅ›ci (os.scandir) dla: {folder_path}")
    scan_start_time = time.time()
    processed_item_count_in_scandir = 0
    SCAN_TIMEOUT_SECONDS = int(config_manager.get_config_value("scan_timeout_per_folder", "120")) # Sekundy

    try:
        logger.debug(f"WywoÅ‚ujÄ™ os.scandir({folder_path})")
        # os.scandir jest iteratorem; bÅ‚Ä™dy mogÄ… wystÄ…piÄ‡ przy samym wywoÅ‚aniu lub podczas iteracji
        with os.scandir(folder_path) as scandir_iterator:
            logger.debug(f"PomyÅ›lnie utworzono iterator os.scandir dla {folder_path}")
            for entry in scandir_iterator:
                if time.time() - scan_start_time > SCAN_TIMEOUT_SECONDS:
                    logger.warning(f"â° Przekroczono limit czasu skanowania ({SCAN_TIMEOUT_SECONDS}s) w folderze {folder_path} po {processed_item_count_in_scandir} elementach.")
                    if progress_callback: progress_callback(f"â° Timeout skanowania w {folder_path}")
                    break # Przerwij pÄ™tlÄ™, folder zostanie przetworzony czÄ™Å›ciowo
                
                processed_item_count_in_scandir += 1
                if processed_item_count_in_scandir % 200 == 0 and progress_callback: # Rzadsze raportowanie
                    progress_callback(f"ğŸ“Š Przetworzono {processed_item_count_in_scandir} elementÃ³w w {folder_path}...")

                try:
                    entry_name = entry.name
                    entry_path = entry.path # PeÅ‚na Å›cieÅ¼ka

                    if entry_name.lower() == "index.json":
                        logger.debug(f"PominiÄ™to plik 'index.json': {entry_path}")
                        continue

                    # WaÅ¼ne: follow_symlinks=False dla is_file/is_dir, aby uniknÄ…Ä‡ problemÃ³w z zepsutymi linkami
                    # lub niespodziewanego Å›ledzenia linkÃ³w do plikÃ³w/folderÃ³w poza skanowanym obszarem.
                    if entry.is_file(follow_symlinks=False):
                        file_size_bytes = 0
                        try:
                            # entry.stat() moÅ¼e byÄ‡ szybsze, bo entry juÅ¼ jest "Å›wiadome" pliku
                            stat_result = entry.stat(follow_symlinks=False) 
                            file_size_bytes = stat_result.st_size
                        except OSError as e_stat:
                            logger.error(f"BÅ‚Ä…d odczytu statystyk dla pliku {entry_path}: {e_stat}")
                            # Plik zostanie dodany z rozmiarem 0
                        
                        index_data["folder_info"]["total_size_bytes"] += file_size_bytes
                        index_data["folder_info"]["file_count"] += 1
                        index_data["folder_info"]["archive_count"] += 1 # Utrzymanie logiki

                        is_image = any(entry_name.lower().endswith(ext) for ext in IMAGE_EXTENSIONS)
                        if is_image:
                            image_file_details.append((entry_name, entry_path, file_size_bytes))
                        else: # Plik niebÄ™dÄ…cy obrazem
                            other_file_details.append((entry_name, entry_path, file_size_bytes))

                    elif entry.is_dir(follow_symlinks=False):
                        index_data["folder_info"]["subdir_count"] += 1
                        # Sprawdzamy, czy sam katalog (DirEntry) nie jest linkiem symbolicznym
                        if not entry.is_symlink(): 
                            subdirectories_to_scan_recursively.append(entry_path)
                        else:
                            logger.debug(f"PominiÄ™to rekurencyjne skanowanie linku symbolicznego do katalogu: {entry_path}")
                    else: # Ani plik, ani katalog (np. link symboliczny do nieistniejÄ…cego pliku, urzÄ…dzenie specjalne)
                        logger.debug(f"PominiÄ™to element specjalny (nie plik/katalog lub zepsuty link): {entry_path}")

                except OSError as e_entry: # BÅ‚Ä™dy dla pojedynczego entry (np. permission denied na stat)
                    logger.error(f"BÅ‚Ä…d OSError podczas przetwarzania elementu '{getattr(entry, 'name', 'NieznanyElement')}' w {folder_path}: {e_entry}", exc_info=False) # exc_info=False by nie spamowaÄ‡ logÃ³w
                    if progress_callback: progress_callback(f"BÅ‚Ä…d elementu w {folder_path}: {getattr(entry, 'name', 'NieznanyElement')}")
                    # Kontynuuj z nastÄ™pnym elementem
            
        logger.debug(f"ZakoÅ„czono pÄ™tlÄ™ os.scandir dla {folder_path}. Przetworzono {processed_item_count_in_scandir} elementÃ³w.")

    except PermissionError as e_perm_scandir:
        logger.error(f"âŒ Brak uprawnieÅ„ (PermissionError) do listowania folderu (os.scandir) {folder_path}: {e_perm_scandir}", exc_info=False)
        if progress_callback: progress_callback(f"âŒ Brak uprawnieÅ„ do listowania {folder_path}")
        return # Przerwij przetwarzanie tego folderu
    except OSError as e_os_scandir: # Inne bÅ‚Ä™dy systemowe przy os.scandir
        logger.error(f"âŒ BÅ‚Ä…d OSError podczas listowania (os.scandir) folderu {folder_path}: {e_os_scandir}", exc_info=True)
        if progress_callback: progress_callback(f"âŒ BÅ‚Ä…d listowania folderu {folder_path}: {e_os_scandir}")
        return 
    except Exception as e_unexpected_scan: # Inne, nieprzewidziane bÅ‚Ä™dy
        logger.error(f"âŒ Nieoczekiwany bÅ‚Ä…d podczas skanowania (os.scandir) folderu {folder_path}: {e_unexpected_scan}", exc_info=True)
        if progress_callback: progress_callback(f"âŒ Nieoczekiwany bÅ‚Ä…d w {folder_path}: {e_unexpected_scan}")
        return

    scan_duration = time.time() - scan_start_time
    logger.info(f"â±ï¸ Skanowanie {folder_path} (os.scandir) i zbieranie danych o plikach zajÄ™Å‚o {scan_duration:.2f}s.")
    logger.info(f"ğŸ“Š W {folder_path}: {len(other_file_details)} innych plikÃ³w, {len(image_file_details)} obrazÃ³w, {len(subdirectories_to_scan_recursively)} podfolderÃ³w.")

    # --- Dopasowywanie podglÄ…dÃ³w ---
    # Przygotuj listÄ™ peÅ‚nych Å›cieÅ¼ek obrazÃ³w dla funkcji dopasowujÄ…cej
    full_paths_of_images_in_folder = [details[1] for details in image_file_details]
    # ZbiÃ³r peÅ‚nych Å›cieÅ¼ek obrazÃ³w, ktÃ³re zostaÅ‚y uÅ¼yte jako podglÄ…dy
    used_preview_image_paths = set() 

    logger.debug(f"Rozpoczynam dopasowywanie podglÄ…dÃ³w dla {len(other_file_details)} plikÃ³w niebÄ™dÄ…cych obrazami.")
    for file_name, file_path, file_size_bytes in other_file_details:
        file_basename_no_ext, _ = os.path.splitext(file_name)
        
        file_info_dict = {
            "name": file_name,
            "path_absolute": os.path.abspath(file_path), # os.path.abspath dla pewnoÅ›ci
            "size_bytes": file_size_bytes,
            "size_readable": get_file_size_readable(file_size_bytes),
        }
        
        # WywoÅ‚anie funkcji dopasowujÄ…cej
        matched_preview_path = find_matching_preview_for_file(
            file_basename_no_ext, 
            full_paths_of_images_in_folder, 
            learning_data
        )

        if matched_preview_path:
            file_info_dict["preview_found"] = True
            file_info_dict["preview_name"] = os.path.basename(matched_preview_path)
            file_info_dict["preview_path_absolute"] = os.path.abspath(matched_preview_path)
            index_data["files_with_previews"].append(file_info_dict)
            used_preview_image_paths.add(matched_preview_path) # Dodaj peÅ‚nÄ… Å›cieÅ¼kÄ™
            # logger.info (juÅ¼ jest w find_matching_preview_for_file)
        else:
            file_info_dict["preview_found"] = False
            index_data["files_without_previews"].append(file_info_dict)
            # logger.debug (juÅ¼ jest w find_matching_preview_for_file)

    # --- Dodawanie obrazÃ³w, ktÃ³re nie zostaÅ‚y uÅ¼yte jako podglÄ…dy ---
    logger.debug(f"Dodawanie {len(image_file_details) - len(used_preview_image_paths)} niesparowanych obrazÃ³w do 'other_images'.")
    for img_name, img_path, img_size_bytes in image_file_details:
        if img_path not in used_preview_image_paths:
            index_data["other_images"].append({
                "name": img_name,
                "path_absolute": os.path.abspath(img_path),
                "size_bytes": img_size_bytes,
                "size_readable": get_file_size_readable(img_size_bytes),
            })

    # --- Finalizacja statystyk folderu i zapis index.json ---
    index_data["folder_info"]["total_size_readable"] = get_file_size_readable(index_data["folder_info"]["total_size_bytes"])
    index_data["folder_info"]["scan_date"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    index_json_path = os.path.join(folder_path, "index.json")
    try:
        logger.debug(f"PrÃ³ba zapisu pliku index.json do: {index_json_path}")
        with open(index_json_path, "w", encoding="utf-8") as f:
            json.dump(index_data, f, indent=4, ensure_ascii=False)
        logger.info(f"ğŸ’¾ Zapisano plik index.json: {index_json_path}")
        if progress_callback:
            progress_callback(f"ğŸ’¾ Zapisano: {index_json_path}")
    except IOError as e_io_write:
        msg = f"âŒ BÅ‚Ä…d zapisu pliku index.json ({index_json_path}): {e_io_write}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)
    except Exception as e_json_write: # Inne bÅ‚Ä™dy np. z serializacjÄ… (maÅ‚o prawdopodobne tutaj)
        msg = f"âŒ Nieoczekiwany bÅ‚Ä…d podczas zapisu index.json ({index_json_path}): {e_json_write}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)


    # --- Przetwarzanie podfolderÃ³w (rekurencja) ---
    logger.debug(f"Znaleziono {len(subdirectories_to_scan_recursively)} podfolderÃ³w do rekurencyjnego skanowania.")
    for subdir_path in subdirectories_to_scan_recursively:
        logger.info(f"â¤µï¸ PrzechodzÄ™ do przetwarzania podfolderu: {subdir_path}")
        # WaÅ¼ne: przekazujemy progress_callback dalej
        process_folder(subdir_path, progress_callback) 


def process_folder_with_retry(folder_path, max_retries=3, progress_callback=None):
    """Przetwarza folder z mechanizmem ponownych prÃ³b w przypadku bÅ‚Ä™dÃ³w dostÄ™pu."""
    logger.debug(f"RozpoczÄ™cie przetwarzania folderu z mechanizmem retry: {folder_path} (max_retries={max_retries})")
    
    # Ustawienie domyÅ›lnego retry_delay jeÅ›li nie ma w konfiguracji
    retry_delay_seconds = float(config_manager.get_config_value("retry_delay_seconds", "0.5"))

    for attempt in range(max_retries):
        try:
            process_folder(folder_path, progress_callback)
            return # Sukces, wyjdÅº z funkcji
        except PermissionError as e_perm: # Tylko PermissionError jest tutaj retry-able
            logger.warning(f"BÅ‚Ä…d dostÄ™pu (PermissionError) przy przetwarzaniu {folder_path} - prÃ³ba {attempt + 1}/{max_retries}: {e_perm}")
            if progress_callback:
                progress_callback(f"BÅ‚Ä…d dostÄ™pu {folder_path} (prÃ³ba {attempt + 1}), ponawiam za {retry_delay_seconds}s...")
            
            if attempt == max_retries - 1:
                msg = f"ğŸš« Nie udaÅ‚o siÄ™ uzyskaÄ‡ dostÄ™pu do folderu {folder_path} po {max_retries} prÃ³bach z powodu PermissionError."
                logger.error(msg)
                if progress_callback: progress_callback(msg)
                # Nie rzucamy wyjÄ…tku dalej, aby skanowanie mogÅ‚o kontynuowaÄ‡ inne foldery,
                # chyba Å¼e chcemy innego zachowania. Tutaj logujemy i koÅ„czymy dla tego folderu.
                return 
            time.sleep(retry_delay_seconds)
        # Inne wyjÄ…tki z process_folder (np. OSError, RuntimeError) nie sÄ… tutaj Å‚apane,
        # aby mogÅ‚y byÄ‡ obsÅ‚uÅ¼one wyÅ¼ej lub przerwaÄ‡ skanowanie, jeÅ›li sÄ… krytyczne.
        # process_folder sam loguje swoje bÅ‚Ä™dy.

    logger.debug(f"ZakoÅ„czono (lub przerwano retry) przetwarzanie dla: {folder_path}")


def start_scanning(root_folder_path, progress_callback=None):
    """Rozpoczyna skanowanie od podanego folderu gÅ‚Ã³wnego."""
    logger.info(f"ğŸš€ Rozpoczynam skanowanie od folderu gÅ‚Ã³wnego: {root_folder_path}")
    if progress_callback: progress_callback(f"ğŸš€ Rozpoczynam skanowanie: {root_folder_path}")

    if not os.path.isdir(root_folder_path): # SprawdÅº czy to folder przed os.access
        msg = f"âŒ BÅ‚Ä…d: ÅšcieÅ¼ka '{root_folder_path}' nie jest folderem lub nie istnieje."
        logger.error(msg)
        if progress_callback: progress_callback(msg)
        return

    try:
        if not os.access(root_folder_path, os.R_OK):
            msg = f"âŒ Brak uprawnieÅ„ do odczytu folderu gÅ‚Ã³wnego: {root_folder_path}"
            logger.error(msg)
            if progress_callback: progress_callback(msg)
            return

        # Sprawdzenie czy folder nie jest pusty (opcjonalne, moÅ¼e byÄ‡ mylÄ…ce jeÅ›li zawiera tylko podfoldery)
        # try:
        #     if not os.listdir(root_folder_path): # listdir moÅ¼e byÄ‡ wolne dla duÅ¼ych folderÃ³w
        #         msg = f"âš ï¸ Folder gÅ‚Ã³wny jest pusty (nie zawiera plikÃ³w ani podfolderÃ³w na pierwszym poziomie): {root_folder_path}"
        #         logger.warning(msg)
        #         if progress_callback: progress_callback(msg)
        # except OSError as e_listdir_root:
        #     logger.warning(f"Nie moÅ¼na sprawdziÄ‡ zawartoÅ›ci folderu gÅ‚Ã³wnego {root_folder_path} z os.listdir: {e_listdir_root}")

        # Uruchom skanowanie z mechanizmem retry dla folderu gÅ‚Ã³wnego,
        # a nastÄ™pnie rekurencyjnie dla podfolderÃ³w (obsÅ‚ugiwane wewnÄ…trz process_folder)
        max_retries_for_scan = int(config_manager.get_config_value("max_scan_retries", "3"))
        process_folder_with_retry(root_folder_path, max_retries=max_retries_for_scan, progress_callback=progress_callback)

        logger.info("âœ… Skanowanie zakoÅ„czone.")
        if progress_callback: progress_callback("âœ… Skanowanie zakoÅ„czone.")

    except Exception as e_critical: # Åapanie wszelkich innych, nieprzewidzianych bÅ‚Ä™dÃ³w na najwyÅ¼szym poziomie
        msg = f"ğŸ’¥ Krytyczny bÅ‚Ä…d podczas operacji start_scanning dla '{root_folder_path}': {e_critical}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)
        # MoÅ¼na zdecydowaÄ‡ o ponownym rzuceniu wyjÄ…tku, jeÅ›li aplikacja gÅ‚Ã³wna ma go obsÅ‚uÅ¼yÄ‡
        # raise


def quick_rescan_folder(folder_path, progress_callback=None):
    """Szybkie ponowne skanowanie folderu po modyfikacji plikÃ³w"""
    logger.info(f"ğŸ”„ Rozpoczynam szybkie ponowne skanowanie folderu: {folder_path}")
    if progress_callback:
        progress_callback(f"ğŸ”„ Ponowne skanowanie: {folder_path}")
    
    # UÅ¼yj process_folder bezpoÅ›rednio (retry jest bardziej na poziomie caÅ‚ego skanowania lub pierwszego dostÄ™pu)
    # MoÅ¼na dodaÄ‡ retry, jeÅ›li jest taka potrzeba specyficznie dla rescan.
    try:
        process_folder(folder_path, progress_callback)
        logger.info(f"âœ… Szybkie ponowne skanowanie folderu {folder_path} zakoÅ„czone.")
        if progress_callback: progress_callback(f"âœ… Ponowne skanowanie {folder_path} zakoÅ„czone.")
    except Exception as e:
        msg = f"âŒ BÅ‚Ä…d podczas szybkiego ponownego skanowania {folder_path}: {e}"
        logger.error(msg, exc_info=True)
        if progress_callback: progress_callback(msg)


if __name__ == "__main__":
    print("--- Rozpoczynam testowanie scanner_logic.py ---")

    # Ustawienia testowe
    # MoÅ¼esz chcieÄ‡ ustawiÄ‡ enable_file_logging na True, aby zobaczyÄ‡ szczegÃ³Å‚owe logi w pliku
    # logger = setup_logger(enable_file_logging=False) # Lub True
    # config_manager moÅ¼na by zamockowaÄ‡ lub utworzyÄ‡ tymczasowy plik config.json
    # Na potrzeby tego testu, zakÅ‚adamy, Å¼e config_manager.get_config_value zwrÃ³ci domyÅ›lne wartoÅ›ci.
    
    # --- Tworzenie tymczasowej struktury folderÃ³w i plikÃ³w ---
    base_test_dir = Path("./test_scan_environment_no_archive") # UÅ¼yj Å›cieÅ¼ki wzglÄ™dnej dla Å‚atwiejszego czyszczenia
    
    if base_test_dir.exists():
        import shutil
        print(f"Usuwam istniejÄ…cy folder testowy: {base_test_dir.resolve()}")
        try:
            shutil.rmtree(base_test_dir)
        except OSError as e:
            print(f"Nie udaÅ‚o siÄ™ usunÄ…Ä‡ starego folderu testowego: {e}. Test moÅ¼e nie byÄ‡ czysty.")
            # exit(1) # MoÅ¼na przerwaÄ‡, jeÅ›li czysty test jest krytyczny

    print(f"TworzÄ™ nowÄ… strukturÄ™ testowÄ… w: {base_test_dir.resolve()}")
    
    # GÅ‚Ã³wny folder testowy
    main_folder = base_test_dir / "main_scan_dir"
    main_folder.mkdir(parents=True, exist_ok=True)

    # Podfolder
    sub_folder = main_folder / "subfolder_A"
    sub_folder.mkdir(exist_ok=True)

    # Podfolder w podfolderze (gÅ‚Ä™bsza rekurencja)
    sub_sub_folder = sub_folder / "sub_sub_B"
    sub_sub_folder.mkdir(exist_ok=True)

    # Pliki w folderze gÅ‚Ã³wnym
    (main_folder / "document_alpha.txt").write_text("Content of document alpha.")
    (main_folder / "document_alpha.jpg").write_text("Fake JPEG for alpha") # PodglÄ…d
    (main_folder / "presentation_beta.pdf").write_text("Content of presentation beta.")
    (main_folder / "presentation_beta_preview.png").write_text("Fake PNG for beta") # PodglÄ…d
    (main_folder / "archive_gamma with spaces.zip").write_text("Fake ZIP content gamma.") # Celowo ze spacjami
    (main_folder / "archive gamma with spaces_cover.gif").write_text("Fake GIF for gamma") # PodglÄ…d
    (main_folder / "loose_image_delta.webp").write_text("Fake WebP delta") # Obraz bez pary
    (main_folder / "no_preview_file_epsilon.docx").write_text("Docx without preview.")
    (main_folder / "index.json").write_text("{}") # Stary index.json, powinien byÄ‡ nadpisany

    # Pliki w podfolderze
    (sub_folder / "notes_zeta.md").write_text("Markdown notes zeta.")
    (sub_folder / "notes_zeta-001.jpg").write_text("Fake JPEG for zeta") # PodglÄ…d
    (sub_folder / "image_only_eta.avif").write_text("Fake AVIF eta")

    # Pliki w pod-podfolderze
    (sub_sub_folder / "final_doc_theta.rtf").write_text("Rich text theta.")
    # Brak podglÄ…du dla final_doc_theta

    # Plik danych uczenia siÄ™
    learning_data_content = [
        {"archive_basename": "archive_gamma with spaces", "image_basename": "archive gamma with spaces_cover"},
        {"archive_basename": "document_alpha", "image_basename": "document_alpha"}, # Mimo Å¼e pasuje, testujemy czy nauka dziaÅ‚a
        {"archive_basename": "non_existent_archive", "image_basename": "non_existent_image_preview"} # Dla testu
    ]
    learning_file_path = base_test_dir / "learning_data_test.json"
    with open(learning_file_path, "w", encoding="utf-8") as lf:
        json.dump(learning_data_content, lf, indent=2)
    
    # Mock config_manager.get_config_value jeÅ›li nie jest dostÄ™pny lub chcemy nadpisaÄ‡
    # W tym przykÅ‚adzie zakÅ‚adamy, Å¼e config_manager.py istnieje i `get_config_value` 
    # ma sensowne wartoÅ›ci domyÅ›lne lub odczytuje je z pliku konfiguracyjnego.
    # MoÅ¼na by to zamockowaÄ‡ tak:
    original_get_config = config_manager.get_config_value
    def mocked_get_config_value(key, default=None):
        if key == "learning_data_file":
            return str(learning_file_path.resolve())
        if key == "scan_timeout_per_folder":
            return "30" # KrÃ³tki timeout dla testu
        # ... inne klucze
        return original_get_config(key, default) # lub po prostu `default`
    
    config_manager.get_config_value = mocked_get_config_value
    logger.info(f"UÅ¼ywam mockowanego config_manager.get_config_value, plik nauki: {learning_file_path.resolve()}")


    def simple_progress_logger(message):
        print(f"[PROGRESS] {message}")

    print(f"\n--- Rozpoczynam skanowanie testowe w: {main_folder.resolve()} ---")
    try:
        start_scanning(str(main_folder.resolve()), simple_progress_logger)
    except Exception as e:
        print(f"!!! KRYTYCZNY BÅÄ„D PODCZAS TESTU start_scanning: {e}")
        logger.error("Krytyczny bÅ‚Ä…d w __main__ podczas start_scanning", exc_info=True)

    print(f"\n--- Skanowanie testowe zakoÅ„czone. SprawdÅº pliki index.json w: ---")
    print(f" - {main_folder.resolve()}")
    print(f" - {sub_folder.resolve()}")
    print(f" - {sub_sub_folder.resolve()}")
    print(f"Oraz logi w konsoli / folderze 'logs'.")

    # PrzywrÃ³cenie oryginalnej funkcji config_manager, jeÅ›li byÅ‚a mockowana
    config_manager.get_config_value = original_get_config

    # Opcjonalnie: Uruchomienie debugowania dopasowaÅ„ dla jednego z folderÃ³w
    # print(f"\n--- TestujÄ™ log_file_matching_debug dla: {main_folder.resolve()} ---")
    # log_file_matching_debug(str(main_folder.resolve()), simple_progress_logger)

    print("\n--- Testowanie zakoÅ„czone ---")